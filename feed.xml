<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://ashishnandagawali.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ashishnandagawali.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-02T05:53:34+00:00</updated><id>https://ashishnandagawali.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Deepseek API Usage with Langchain</title><link href="https://ashishnandagawali.github.io/blog/2025/Deepseek-Langchain-api/" rel="alternate" type="text/html" title="Deepseek API Usage with Langchain"/><published>2025-02-01T20:00:00+00:00</published><updated>2025-02-01T20:00:00+00:00</updated><id>https://ashishnandagawali.github.io/blog/2025/Deepseek-Langchain-api</id><content type="html" xml:base="https://ashishnandagawali.github.io/blog/2025/Deepseek-Langchain-api/"><![CDATA[<h1 id="deepseek-api-usage-with-langchain">Deepseek API Usage with Langchain</h1> <p>In this article we’ll see how we can use the deepseek api from Lanchain framework as per documentation provided by Deepseek</p> <ol> <li>Install following library <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="n">langchain_openai</span>
</code></pre></div> </div> </li> <li>Import BaseChatOpenAI class from the Langchain chat models <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="kn">from</span> <span class="n">langchain_openai.chat_models.base</span> <span class="kn">import</span> <span class="n">BaseChatOpenAI</span>
</code></pre></div> </div> </li> <li> <p>Now create an BaseChatOpenAI object which will be used across our page.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="n">llm</span> <span class="o">=</span> <span class="nc">BaseChatOpenAI</span><span class="p">(</span>
         <span class="n">model</span><span class="o">=</span><span class="sh">'</span><span class="s">deepseek-chat</span><span class="sh">'</span><span class="p">,</span> 
         <span class="n">openai_api_key</span><span class="o">=</span><span class="sh">'</span><span class="s">&lt;Your API Key&gt;</span><span class="sh">'</span>
         <span class="n">openai_api_base</span><span class="o">=</span><span class="sh">'</span><span class="s">https://api.deepseek.com</span><span class="sh">'</span><span class="p">,</span>
         <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1024</span>
     <span class="p">)</span>
</code></pre></div> </div> </li> <li>lets give an sample prompt message to check whether the api is working fine. <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="n">response</span> <span class="o">=</span> <span class="n">llm</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span><span class="sh">"</span><span class="s">Hi!</span><span class="sh">"</span><span class="p">)</span>
     <span class="nf">print</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">content</span><span class="p">)</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="n">Hello</span><span class="err">!</span> <span class="n">How</span> <span class="n">can</span> <span class="n">I</span> <span class="n">assist</span> <span class="n">you</span> <span class="n">today</span><span class="err">?</span> 
</code></pre></div> </div> </li> <li> <p>lets givea proper message and see the output to ensure that API is responding as expected</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
         <span class="p">(</span>
             <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">You are a helpful assistant that translates English to Persian. Translate the user sentence.</span><span class="sh">"</span><span class="p">,</span>
         <span class="p">),</span>
         <span class="p">(</span><span class="sh">"</span><span class="s">human</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">I love programming.</span><span class="sh">"</span><span class="p">),</span>
     <span class="p">]</span>
     <span class="n">ai_msg</span> <span class="o">=</span> <span class="n">llm</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
     <span class="n">ai_msg</span><span class="p">.</span><span class="n">content</span>
</code></pre></div> </div> </li> <li>Check with complete message given to system <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    
     <span class="kn">from</span> <span class="n">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
        
     <span class="n">prompt</span> <span class="o">=</span> <span class="nc">ChatPromptTemplate</span><span class="p">(</span>
         <span class="p">[</span>
             <span class="p">(</span>
                 <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span>
                 <span class="sh">"</span><span class="s">You are a helpful assistant that translates {input_language} to {output_language}.</span><span class="sh">"</span><span class="p">,</span>
             <span class="p">),</span>
             <span class="p">(</span><span class="sh">"</span><span class="s">human</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">{input}</span><span class="sh">"</span><span class="p">),</span>
         <span class="p">]</span>
     <span class="p">)</span>
        
     <span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">llm</span>
     <span class="n">chain</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span>
         <span class="p">{</span>
             <span class="sh">"</span><span class="s">input_language</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">English</span><span class="sh">"</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">output_language</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">German</span><span class="sh">"</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">input</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">I love agentic AI.</span><span class="sh">"</span><span class="p">,</span>
         <span class="p">}</span>
     <span class="p">)</span>
</code></pre></div> </div> </li> <li> <p>Observe the output, esepcailly the KV Cache or content caching portion. <em>** AIMessage(content=’Ich liebe agentische KI.’, additional_kwargs={‘refusal’: None}, response_metadata={‘token_usage’: {‘completion_tokens’: 7, ‘prompt_tokens’: 20, ‘total_tokens’: 27, ‘completion_tokens_details’: None, ‘prompt_tokens_details’: {‘audio_tokens’: None, ‘cached_tokens’: 0}, ‘prompt_cache_hit_tokens’: 0, ‘prompt_cache_miss_tokens’: 20}, ‘model_name’: ‘deepseek-chat’, ‘system_fingerprint’: ‘fp_3a5770e1b4’, ‘finish_reason’: ‘stop’, ‘logprobs’: None}, id=’run-46ca6f2a-21ef-45f4-83f6-814c07fab391-0’, usage_metadata={‘input_tokens’: 20, ‘output_tokens’: 7, ‘total_tokens’: 27, ‘input_token_details’: {‘cache_read’: 0}, ‘output_token_details’: {}}) **</em></p> </li> <li>You can find working <a href="https://github.com/ashishnandagawali/agentic-ai/blob/0096abadca77518e8af77fa36df0cc15a64d929e/Langchain_deepseek.ipynb">google colab file</a> in my github repo -</li> </ol>]]></content><author><name></name></author><category term="Code"/><category term="Deepseek,"/><category term="API,"/><category term="Langchain"/><summary type="html"><![CDATA[This blog post describes way to connect Deepseep API using Langchain]]></summary></entry></feed>