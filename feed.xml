<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://ashishnandagawali.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ashishnandagawali.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-02T06:07:59+00:00</updated><id>https://ashishnandagawali.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Deepseek API Usage with Langchain</title><link href="https://ashishnandagawali.github.io/blog/2025/Deepseek-Langchain-api/" rel="alternate" type="text/html" title="Deepseek API Usage with Langchain"/><published>2025-02-01T20:00:00+00:00</published><updated>2025-02-01T20:00:00+00:00</updated><id>https://ashishnandagawali.github.io/blog/2025/Deepseek-Langchain-api</id><content type="html" xml:base="https://ashishnandagawali.github.io/blog/2025/Deepseek-Langchain-api/"><![CDATA[<h1 id="deepseek-api-usage-with-langchain">Deepseek API Usage with Langchain</h1> <p>In this article weâ€™ll see how we can use the deepseek api from Lanchain framework as per documentation provided by Deepseek.</p> <ol> <li>Install following library <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="sh">'</span><span class="s">!pip3 install langchain_openai</span><span class="sh">'</span>
</code></pre></div> </div> </li> <li>Import BaseChatOpenAI class from the Langchain chat models <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="kn">from</span> <span class="n">langchain_openai.chat_models.base</span> <span class="kn">import</span> <span class="n">BaseChatOpenAI</span>
</code></pre></div> </div> </li> <li> <p>Now create an BaseChatOpenAI object which will be used across our page.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="n">llm</span> <span class="o">=</span> <span class="nc">BaseChatOpenAI</span><span class="p">(</span>
         <span class="n">model</span><span class="o">=</span><span class="sh">'</span><span class="s">deepseek-chat</span><span class="sh">'</span><span class="p">,</span> 
         <span class="n">openai_api_key</span><span class="o">=</span><span class="sh">'</span><span class="s">&lt;Your API Key&gt;</span><span class="sh">'</span>
         <span class="n">openai_api_base</span><span class="o">=</span><span class="sh">'</span><span class="s">https://api.deepseek.com</span><span class="sh">'</span><span class="p">,</span>
         <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1024</span>
     <span class="p">)</span>
</code></pre></div> </div> </li> <li>lets give an sample prompt message to check whether the api is working fine. <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="n">response</span> <span class="o">=</span> <span class="n">llm</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span><span class="sh">"</span><span class="s">Hi!</span><span class="sh">"</span><span class="p">)</span>
     <span class="nf">print</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">content</span><span class="p">)</span>
</code></pre></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="n">Hello</span><span class="err">!</span> <span class="n">How</span> <span class="n">can</span> <span class="n">I</span> <span class="n">assist</span> <span class="n">you</span> <span class="n">today</span><span class="err">?</span> 
</code></pre></div> </div> </li> <li> <p>lets givea proper message and see the output to ensure that API is responding as expected</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
         <span class="p">(</span>
             <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">You are a helpful assistant that translates English to Persian. Translate the user sentence.</span><span class="sh">"</span><span class="p">,</span>
         <span class="p">),</span>
         <span class="p">(</span><span class="sh">"</span><span class="s">human</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">I love programming.</span><span class="sh">"</span><span class="p">),</span>
     <span class="p">]</span>
     <span class="n">ai_msg</span> <span class="o">=</span> <span class="n">llm</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
     <span class="n">ai_msg</span><span class="p">.</span><span class="n">content</span>
</code></pre></div> </div> </li> <li>Check with complete message given to system <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    
     <span class="kn">from</span> <span class="n">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
        
     <span class="n">prompt</span> <span class="o">=</span> <span class="nc">ChatPromptTemplate</span><span class="p">(</span>
         <span class="p">[</span>
             <span class="p">(</span>
                 <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span>
                 <span class="sh">"</span><span class="s">You are a helpful assistant that translates {input_language} to {output_language}.</span><span class="sh">"</span><span class="p">,</span>
             <span class="p">),</span>
             <span class="p">(</span><span class="sh">"</span><span class="s">human</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">{input}</span><span class="sh">"</span><span class="p">),</span>
         <span class="p">]</span>
     <span class="p">)</span>
        
     <span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">llm</span>
     <span class="n">chain</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span>
         <span class="p">{</span>
             <span class="sh">"</span><span class="s">input_language</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">English</span><span class="sh">"</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">output_language</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">German</span><span class="sh">"</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">input</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">I love agentic AI.</span><span class="sh">"</span><span class="p">,</span>
         <span class="p">}</span>
     <span class="p">)</span>
</code></pre></div> </div> </li> <li>Observe the output, esepcailly the KV Cache or content caching portion. <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="nc">AIMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="sh">'</span><span class="s">Ich liebe agentische KI.</span><span class="sh">'</span><span class="p">,</span> <span class="n">additional_kwargs</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">refusal</span><span class="sh">'</span><span class="p">:</span> <span class="bp">None</span><span class="p">},</span> <span class="n">response_metadata</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">token_usage</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">completion_tokens</span><span class="sh">'</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="sh">'</span><span class="s">prompt_tokens</span><span class="sh">'</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="sh">'</span><span class="s">total_tokens</span><span class="sh">'</span><span class="p">:</span> <span class="mi">27</span><span class="p">,</span> <span class="sh">'</span><span class="s">completion_tokens_details</span><span class="sh">'</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span> <span class="sh">'</span><span class="s">prompt_tokens_details</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">audio_tokens</span><span class="sh">'</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span> <span class="sh">'</span><span class="s">cached_tokens</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span> <span class="sh">'</span><span class="s">prompt_cache_hit_tokens</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">'</span><span class="s">prompt_cache_miss_tokens</span><span class="sh">'</span><span class="p">:</span> <span class="mi">20</span><span class="p">},</span> <span class="sh">'</span><span class="s">model_name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">deepseek-chat</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">system_fingerprint</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">fp_3a5770e1b4</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">finish_reason</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">logprobs</span><span class="sh">'</span><span class="p">:</span> <span class="bp">None</span><span class="p">},</span> <span class="nb">id</span><span class="o">=</span><span class="sh">'</span><span class="s">run-46ca6f2a-21ef-45f4-83f6-814c07fab391-0</span><span class="sh">'</span><span class="p">,</span> <span class="n">usage_metadata</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">input_tokens</span><span class="sh">'</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="sh">'</span><span class="s">output_tokens</span><span class="sh">'</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="sh">'</span><span class="s">total_tokens</span><span class="sh">'</span><span class="p">:</span> <span class="mi">27</span><span class="p">,</span> <span class="sh">'</span><span class="s">input_token_details</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">cache_read</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span> <span class="sh">'</span><span class="s">output_token_details</span><span class="sh">'</span><span class="p">:</span> <span class="p">{}})</span>
</code></pre></div> </div> </li> <li>You can find working <a href="https://github.com/ashishnandagawali/agentic-ai/blob/0096abadca77518e8af77fa36df0cc15a64d929e/Langchain_deepseek.ipynb">google colab file</a> in my github repo.</li> </ol>]]></content><author><name></name></author><category term="Code"/><category term="Deepseek,"/><category term="API,"/><category term="Langchain"/><summary type="html"><![CDATA[This blog post describes way to connect Deepseep API using Langchain]]></summary></entry></feed>